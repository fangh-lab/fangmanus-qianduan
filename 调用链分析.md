# OpenManus é¡¹ç›®è°ƒç”¨é“¾è¯¦ç»†åˆ†æ

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æäº†è¿è¡Œ `main.py` åï¼Œæ•´ä¸ªç³»ç»Ÿçš„æ‰§è¡Œæµç¨‹å’Œè°ƒç”¨å…³ç³»ã€‚

---

## ä¸€ã€å…¥å£ç‚¹ï¼šmain.py

### 1.1 ç¨‹åºå¯åŠ¨

```1:37:main.py
import argparse
import asyncio

from app.agent.manus import Manus
from app.logger import logger


async def main():
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Run Manus agent with a prompt")
    parser.add_argument(
        "--prompt", type=str, required=False, help="Input prompt for the agent"
    )
    args = parser.parse_args()

    # Create and initialize Manus agent
    agent = await Manus.create()
    try:
        # Use command line prompt if provided, otherwise ask for input
        prompt = args.prompt if args.prompt else input("Enter your prompt: ")
        if not prompt.strip():
            logger.warning("Empty prompt provided.")
            return

        logger.warning("Processing your request...")
        await agent.run(prompt)
        logger.info("Request processing completed.")
    except KeyboardInterrupt:
        logger.warning("Operation interrupted.")
    finally:
        # Ensure agent resources are cleaned up before exiting
        await agent.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
```

### 1.2 æ‰§è¡Œæ­¥éª¤

1. **è§£æå‘½ä»¤è¡Œå‚æ•°**ï¼šæ£€æŸ¥æ˜¯å¦æä¾›äº† `--prompt` å‚æ•°
2. **åˆ›å»º Agent å®ä¾‹**ï¼šè°ƒç”¨ `Manus.create()` åˆ›å»ºå¹¶åˆå§‹åŒ– Agent
3. **è·å–ç”¨æˆ·è¾“å…¥**ï¼š
   - å¦‚æœå‘½ä»¤è¡Œæä¾›äº† `--prompt`ï¼Œä½¿ç”¨å®ƒ
   - å¦åˆ™ï¼Œé€šè¿‡ `input("Enter your prompt: ")` æç¤ºç”¨æˆ·è¾“å…¥
4. **æ‰§è¡Œ Agent**ï¼šè°ƒç”¨ `agent.run(prompt)` å¼€å§‹å¤„ç†è¯·æ±‚
5. **æ¸…ç†èµ„æº**ï¼šåœ¨ `finally` å—ä¸­è°ƒç”¨ `agent.cleanup()`

---

## äºŒã€Agent åˆå§‹åŒ–ï¼šManus.create()

### 2.1 Manus ç±»ç»“æ„

```18:65:app/agent/manus.py
class Manus(ToolCallAgent):
    """A versatile general-purpose agent with support for both local and MCP tools."""

    name: str = "Manus"
    description: str = "A versatile agent that can solve various tasks using multiple tools including MCP-based tools"

    system_prompt: str = SYSTEM_PROMPT.format(directory=config.workspace_root)
    next_step_prompt: str = NEXT_STEP_PROMPT

    max_observe: int = 10000
    max_steps: int = 20

    # MCP clients for remote tool access
    mcp_clients: MCPClients = Field(default_factory=MCPClients)

    # Add general-purpose tools to the tool collection
    available_tools: ToolCollection = Field(
        default_factory=lambda: ToolCollection(
            PythonExecute(),
            BrowserUseTool(),
            StrReplaceEditor(),
            AskHuman(),
            Terminate(),
        )
    )

    special_tool_names: list[str] = Field(default_factory=lambda: [Terminate().name])
    browser_context_helper: Optional[BrowserContextHelper] = None

    # Track connected MCP servers
    connected_servers: Dict[str, str] = Field(
        default_factory=dict
    )  # server_id -> url/command
    _initialized: bool = False

    @model_validator(mode="after")
    def initialize_helper(self) -> "Manus":
        """Initialize basic components synchronously."""
        self.browser_context_helper = BrowserContextHelper(self)
        return self

    @classmethod
    async def create(cls, **kwargs) -> "Manus":
        """Factory method to create and properly initialize a Manus instance."""
        instance = cls(**kwargs)
        await instance.initialize_mcp_servers()
        instance._initialized = True
        return instance
```

### 2.2 åˆå§‹åŒ–æµç¨‹

1. **åˆ›å»ºå®ä¾‹**ï¼š`instance = cls(**kwargs)` åˆ›å»º Manus å®ä¾‹
2. **åˆå§‹åŒ– MCP æœåŠ¡å™¨**ï¼š`await instance.initialize_mcp_servers()` è¿æ¥é…ç½®çš„ MCP æœåŠ¡å™¨
3. **æ ‡è®°å·²åˆå§‹åŒ–**ï¼š`instance._initialized = True`

### 2.3 MCP æœåŠ¡å™¨åˆå§‹åŒ–

```67:89:app/agent/manus.py
    async def initialize_mcp_servers(self) -> None:
        """Initialize connections to configured MCP servers."""
        for server_id, server_config in config.mcp_config.servers.items():
            try:
                if server_config.type == "sse":
                    if server_config.url:
                        await self.connect_mcp_server(server_config.url, server_id)
                        logger.info(
                            f"Connected to MCP server {server_id} at {server_config.url}"
                        )
                elif server_config.type == "stdio":
                    if server_config.command:
                        await self.connect_mcp_server(
                            server_config.command,
                            server_id,
                            use_stdio=True,
                            stdio_args=server_config.args,
                        )
                        logger.info(
                            f"Connected to MCP server {server_id} using command {server_config.command}"
                        )
            except Exception as e:
                logger.error(f"Failed to connect to MCP server {server_id}: {e}")
```

---

## ä¸‰ã€æ‰§è¡Œæµç¨‹ï¼šagent.run()

### 3.1 è°ƒç”¨é“¾

```
agent.run(prompt)
  â†“
BaseAgent.run(request)  [app/agent/base.py]
  â†“
å¾ªç¯æ‰§è¡Œï¼šstep()
  â†“
ReActAgent.step()  [app/agent/react.py]
  â†“
  â”œâ”€â†’ think()  [ToolCallAgent.think() åœ¨ app/agent/toolcall.py]
  â”‚     â†“
  â”‚     LLM.ask_tool()  [app/llm.py]
  â”‚     â†“
  â”‚     è¿”å›å·¥å…·è°ƒç”¨ç»“æœ
  â”‚
  â””â”€â†’ act()  [ToolCallAgent.act() åœ¨ app/agent/toolcall.py]
        â†“
        æ‰§è¡Œå·¥å…·è°ƒç”¨
        â†“
        å°†ç»“æœæ·»åŠ åˆ° memory
```

### 3.2 BaseAgent.run() è¯¦è§£

```116:154:app/agent/base.py
    async def run(self, request: Optional[str] = None) -> str:
        """Execute the agent's main loop asynchronously.

        Args:
            request: Optional initial user request to process.

        Returns:
            A string summarizing the execution results.

        Raises:
            RuntimeError: If the agent is not in IDLE state at start.
        """
        if self.state != AgentState.IDLE:
            raise RuntimeError(f"Cannot run agent from state: {self.state}")

        if request:
            self.update_memory("user", request)

        results: List[str] = []
        async with self.state_context(AgentState.RUNNING):
            while (
                self.current_step < self.max_steps and self.state != AgentState.FINISHED
            ):
                self.current_step += 1
                logger.info(f"Executing step {self.current_step}/{self.max_steps}")
                step_result = await self.step()

                # Check for stuck state
                if self.is_stuck():
                    self.handle_stuck_state()

                results.append(f"Step {self.current_step}: {step_result}")

            if self.current_step >= self.max_steps:
                self.current_step = 0
                self.state = AgentState.IDLE
                results.append(f"Terminated: Reached max steps ({self.max_steps})")
        await SANDBOX_CLIENT.cleanup()
        return "\n".join(results) if results else "No steps executed"
```

**æ‰§è¡Œé€»è¾‘**ï¼š

1. **çŠ¶æ€æ£€æŸ¥**ï¼šç¡®ä¿ Agent å¤„äº IDLE çŠ¶æ€
2. **æ·»åŠ ç”¨æˆ·è¯·æ±‚åˆ°å†…å­˜**ï¼šå¦‚æœæä¾›äº† requestï¼Œè°ƒç”¨ `update_memory("user", request)`
3. **è¿›å…¥è¿è¡ŒçŠ¶æ€**ï¼šä½¿ç”¨ `state_context(AgentState.RUNNING)` ä¸Šä¸‹æ–‡ç®¡ç†å™¨
4. **æ‰§è¡Œå¾ªç¯**ï¼š
   - å¾ªç¯æ¡ä»¶ï¼š`current_step < max_steps` ä¸” `state != FINISHED`
   - æ¯æ¬¡å¾ªç¯ï¼š
     - å¢åŠ æ­¥æ•°ï¼š`current_step += 1`
     - æ‰§è¡Œä¸€æ­¥ï¼š`await self.step()`
     - æ£€æŸ¥æ˜¯å¦å¡ä½ï¼š`is_stuck()`
     - è®°å½•ç»“æœ
5. **æ¸…ç†æ²™ç®±**ï¼š`await SANDBOX_CLIENT.cleanup()`

### 3.3 ReActAgent.step() - Think-Act æ¨¡å¼

```33:38:app/agent/react.py
    async def step(self) -> str:
        """Execute a single step: think and act."""
        should_act = await self.think()
        if not should_act:
            return "Thinking complete - no action needed"
        return await self.act()
```

**æ‰§è¡Œé€»è¾‘**ï¼š

1. **Think é˜¶æ®µ**ï¼š`await self.think()` å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
2. **Act é˜¶æ®µ**ï¼šå¦‚æœ think è¿”å› Trueï¼Œæ‰§è¡Œ `await self.act()`

---

## å››ã€Think é˜¶æ®µï¼šToolCallAgent.think()

### 4.1 å®Œæ•´æµç¨‹

```39:129:app/agent/toolcall.py
    async def think(self) -> bool:
        """Process current state and decide next actions using tools"""
        if self.next_step_prompt:
            user_msg = Message.user_message(self.next_step_prompt)
            self.messages += [user_msg]

        try:
            # Get response with tool options
            response = await self.llm.ask_tool(
                messages=self.messages,
                system_msgs=(
                    [Message.system_message(self.system_prompt)]
                    if self.system_prompt
                    else None
                ),
                tools=self.available_tools.to_params(),
                tool_choice=self.tool_choices,
            )
        except ValueError:
            raise
        except Exception as e:
            # Check if this is a RetryError containing TokenLimitExceeded
            if hasattr(e, "__cause__") and isinstance(e.__cause__, TokenLimitExceeded):
                token_limit_error = e.__cause__
                logger.error(
                    f"ğŸš¨ Token limit error (from RetryError): {token_limit_error}"
                )
                self.memory.add_message(
                    Message.assistant_message(
                        f"Maximum token limit reached, cannot continue execution: {str(token_limit_error)}"
                    )
                )
                self.state = AgentState.FINISHED
                return False
            raise

        self.tool_calls = tool_calls = (
            response.tool_calls if response and response.tool_calls else []
        )
        content = response.content if response and response.content else ""

        # Log response info
        logger.info(f"âœ¨ {self.name}'s thoughts: {content}")
        logger.info(
            f"ğŸ› ï¸ {self.name} selected {len(tool_calls) if tool_calls else 0} tools to use"
        )
        if tool_calls:
            logger.info(
                f"ğŸ§° Tools being prepared: {[call.function.name for call in tool_calls]}"
            )
            logger.info(f"ğŸ”§ Tool arguments: {tool_calls[0].function.arguments}")

        try:
            if response is None:
                raise RuntimeError("No response received from the LLM")

            # Handle different tool_choices modes
            if self.tool_choices == ToolChoice.NONE:
                if tool_calls:
                    logger.warning(
                        f"ğŸ¤” Hmm, {self.name} tried to use tools when they weren't available!"
                    )
                if content:
                    self.memory.add_message(Message.assistant_message(content))
                    return True
                return False

            # Create and add assistant message
            assistant_msg = (
                Message.from_tool_calls(content=content, tool_calls=self.tool_calls)
                if self.tool_calls
                else Message.assistant_message(content)
            )
            self.memory.add_message(assistant_msg)

            if self.tool_choices == ToolChoice.REQUIRED and not self.tool_calls:
                return True  # Will be handled in act()

            # For 'auto' mode, continue with content if no commands but content exists
            if self.tool_choices == ToolChoice.AUTO and not self.tool_calls:
                return bool(content)

            return bool(self.tool_calls)
        except Exception as e:
            logger.error(f"ğŸš¨ Oops! The {self.name}'s thinking process hit a snag: {e}")
            self.memory.add_message(
                Message.assistant_message(
                    f"Error encountered while processing: {str(e)}"
                )
            )
            return False
```

**æ‰§è¡Œæ­¥éª¤**ï¼š

1. **æ·»åŠ ä¸‹ä¸€æ­¥æç¤º**ï¼šå¦‚æœæœ‰ `next_step_prompt`ï¼Œå°†å…¶ä½œä¸ºç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ° messages
2. **è°ƒç”¨ LLM**ï¼š`await self.llm.ask_tool()` è·å– LLM å“åº”
   - ä¼ å…¥å‚æ•°ï¼š
     - `messages`ï¼šå½“å‰å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
     - `system_msgs`ï¼šç³»ç»Ÿæç¤º
     - `tools`ï¼šå¯ç”¨å·¥å…·åˆ—è¡¨ï¼ˆé€šè¿‡ `available_tools.to_params()` è½¬æ¢ï¼‰
     - `tool_choice`ï¼šå·¥å…·é€‰æ‹©ç­–ç•¥ï¼ˆAUTO/REQUIRED/NONEï¼‰
3. **æå–å·¥å…·è°ƒç”¨**ï¼šä»å“åº”ä¸­æå– `tool_calls` å’Œ `content`
4. **æ·»åŠ åˆ°å†…å­˜**ï¼šå°†åŠ©æ‰‹å“åº”æ·»åŠ åˆ° memory
5. **è¿”å›æ˜¯å¦ç»§ç»­**ï¼šæ ¹æ®å·¥å…·è°ƒç”¨æƒ…å†µè¿”å› True/False

### 4.2 LLM.ask_tool() è°ƒç”¨

```644:743:app/llm.py
    async def ask_tool(
        self,
        messages: List[Union[dict, Message]],
        system_msgs: Optional[List[Union[dict, Message]]] = None,
        timeout: int = 300,
        tools: Optional[List[dict]] = None,
        tool_choice: TOOL_CHOICE_TYPE = ToolChoice.AUTO,  # type: ignore
        temperature: Optional[float] = None,
        **kwargs,
    ) -> ChatCompletionMessage | None:
        """
        Ask LLM using functions/tools and return the response.

        Args:
            messages: List of conversation messages
            system_msgs: Optional system messages to prepend
            timeout: Request timeout in seconds
            tools: List of tools to use
            tool_choice: Tool choice strategy
            temperature: Sampling temperature for the response

        Returns:
            ChatCompletionMessage: The model's response
        """
        try:
            # Validate tool_choice
            if tool_choice not in TOOL_CHOICE_VALUES:
                raise ValueError(f"Invalid tool_choice: {tool_choice}")

            # Check if the model supports images
            supports_images = self.model in MULTIMODAL_MODELS

            # Format messages
            if system_msgs:
                system_msgs = self.format_messages(system_msgs, supports_images)
                messages = system_msgs + self.format_messages(messages, supports_images)
            else:
                messages = self.format_messages(messages, supports_images)

            # Calculate input token count
            input_tokens = self.count_message_tokens(messages)

            # If there are tools, calculate token count for tool descriptions
            tools_tokens = 0
            if tools:
                for tool in tools:
                    tools_tokens += self.count_tokens(str(tool))

            input_tokens += tools_tokens

            # Check if token limits are exceeded
            if not self.check_token_limit(input_tokens):
                error_message = self.get_limit_error_message(input_tokens)
                # Raise a special exception that won't be retried
                raise TokenLimitExceeded(error_message)

            # Validate tools if provided
            if tools:
                for tool in tools:
                    if not isinstance(tool, dict) or "type" not in tool:
                        raise ValueError("Each tool must be a dict with 'type' field")

            # Set up the completion request
            params = {
                "model": self.model,
                "messages": messages,
                "tools": tools,
                "tool_choice": tool_choice,
                "timeout": timeout,
                **kwargs,
            }

            if self.model in REASONING_MODELS:
                params["max_completion_tokens"] = self.max_tokens
            else:
                params["max_tokens"] = self.max_tokens
                params["temperature"] = (
                    temperature if temperature is not None else self.temperature
                )

            params["stream"] = False  # Always use non-streaming for tool requests
            response: ChatCompletion = await self.client.chat.completions.create(
                **params
            )

            # Check if response is valid
            if not response.choices or not response.choices[0].message:
                print(response)
                # raise ValueError("Invalid or empty response from LLM")
                return None

            # Update token counts
            self.update_token_count(
```

**å…³é”®æ­¥éª¤**ï¼š

1. **éªŒè¯å‚æ•°**ï¼šæ£€æŸ¥ tool_choice æ˜¯å¦æœ‰æ•ˆ
2. **æ ¼å¼åŒ–æ¶ˆæ¯**ï¼šå°†æ¶ˆæ¯è½¬æ¢ä¸º API æ ¼å¼
3. **è®¡ç®— token**ï¼šè®¡ç®—è¾“å…¥ token æ•°é‡
4. **æ£€æŸ¥ token é™åˆ¶**ï¼šå¦‚æœè¶…å‡ºé™åˆ¶ï¼ŒæŠ›å‡º `TokenLimitExceeded`
5. **éªŒè¯å·¥å…·**ï¼šç¡®ä¿å·¥å…·æ ¼å¼æ­£ç¡®
6. **è°ƒç”¨ API**ï¼š`await self.client.chat.completions.create(**params)`
7. **è¿”å›ç»“æœ**ï¼šè¿”å› `ChatCompletionMessage`

---

## äº”ã€Act é˜¶æ®µï¼šToolCallAgent.act()

### 5.1 æ‰§è¡Œå·¥å…·è°ƒç”¨

```131:164:app/agent/toolcall.py
    async def act(self) -> str:
        """Execute tool calls and handle their results"""
        if not self.tool_calls:
            if self.tool_choices == ToolChoice.REQUIRED:
                raise ValueError(TOOL_CALL_REQUIRED)

            # Return last message content if no tool calls
            return self.messages[-1].content or "No content or commands to execute"

        results = []
        for command in self.tool_calls:
            # Reset base64_image for each tool call
            self._current_base64_image = None

            result = await self.execute_tool(command)

            if self.max_observe:
                result = result[: self.max_observe]

            logger.info(
                f"ğŸ¯ Tool '{command.function.name}' completed its mission! Result: {result}"
            )

            # Add tool response to memory
            tool_msg = Message.tool_message(
                content=result,
                tool_call_id=command.id,
                name=command.function.name,
                base64_image=self._current_base64_image,
            )
            self.memory.add_message(tool_msg)
            results.append(result)

        return "\n\n".join(results)
```

**æ‰§è¡Œæ­¥éª¤**ï¼š

1. **æ£€æŸ¥å·¥å…·è°ƒç”¨**ï¼šå¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€åä¸€æ¡æ¶ˆæ¯å†…å®¹
2. **éå†å·¥å…·è°ƒç”¨**ï¼šå¯¹æ¯ä¸ªå·¥å…·è°ƒç”¨æ‰§è¡Œï¼š
   - é‡ç½® `_current_base64_image`
   - æ‰§è¡Œå·¥å…·ï¼š`await self.execute_tool(command)`
   - æˆªæ–­ç»“æœï¼ˆå¦‚æœè®¾ç½®äº† `max_observe`ï¼‰
   - åˆ›å»ºå·¥å…·æ¶ˆæ¯å¹¶æ·»åŠ åˆ° memory
3. **è¿”å›ç»“æœ**ï¼šè¿”å›æ‰€æœ‰å·¥å…·æ‰§è¡Œç»“æœçš„åˆå¹¶

### 5.2 execute_tool() è¯¦è§£

```166:208:app/agent/toolcall.py
    async def execute_tool(self, command: ToolCall) -> str:
        """Execute a single tool call with robust error handling"""
        if not command or not command.function or not command.function.name:
            return "Error: Invalid command format"

        name = command.function.name
        if name not in self.available_tools.tool_map:
            return f"Error: Unknown tool '{name}'"

        try:
            # Parse arguments
            args = json.loads(command.function.arguments or "{}")

            # Execute the tool
            logger.info(f"ğŸ”§ Activating tool: '{name}'...")
            result = await self.available_tools.execute(name=name, tool_input=args)

            # Handle special tools
            await self._handle_special_tool(name=name, result=result)

            # Check if result is a ToolResult with base64_image
            if hasattr(result, "base64_image") and result.base64_image:
                # Store the base64_image for later use in tool_message
                self._current_base64_image = result.base64_image

            # Format result for display (standard case)
            observation = (
                f"Observed output of cmd `{name}` executed:\n{str(result)}"
                if result
                else f"Cmd `{name}` completed with no output"
            )

            return observation
        except json.JSONDecodeError:
            error_msg = f"Error parsing arguments for {name}: Invalid JSON format"
            logger.error(
                f"ğŸ“ Oops! The arguments for '{name}' don't make sense - invalid JSON, arguments:{command.function.arguments}"
            )
            return f"Error: {error_msg}"
        except Exception as e:
            error_msg = f"âš ï¸ Tool '{name}' encountered a problem: {str(e)}"
            logger.exception(error_msg)
            return f"Error: {error_msg}"
```

**æ‰§è¡Œæ­¥éª¤**ï¼š

1. **éªŒè¯å‘½ä»¤æ ¼å¼**ï¼šæ£€æŸ¥å‘½ä»¤å’Œå‡½æ•°åæ˜¯å¦æœ‰æ•ˆ
2. **æ£€æŸ¥å·¥å…·æ˜¯å¦å­˜åœ¨**ï¼šåœ¨ `available_tools.tool_map` ä¸­æŸ¥æ‰¾å·¥å…·
3. **è§£æå‚æ•°**ï¼šä½¿ç”¨ `json.loads()` è§£æå·¥å…·å‚æ•°
4. **æ‰§è¡Œå·¥å…·**ï¼š`await self.available_tools.execute(name=name, tool_input=args)`
5. **å¤„ç†ç‰¹æ®Šå·¥å…·**ï¼šå¦‚æœæ˜¯ç‰¹æ®Šå·¥å…·ï¼ˆå¦‚ Terminateï¼‰ï¼Œå¯èƒ½ä¼šæ”¹å˜ Agent çŠ¶æ€
6. **å¤„ç†ç»“æœ**ï¼šæå– base64_imageï¼ˆå¦‚æœæœ‰ï¼‰
7. **æ ¼å¼åŒ–ç»“æœ**ï¼šå°†ç»“æœæ ¼å¼åŒ–ä¸ºè§‚å¯Ÿå­—ç¬¦ä¸²

### 5.3 ToolCollection.execute()

```25:35:app/tool/tool_collection.py
    async def execute(
        self, *, name: str, tool_input: Dict[str, Any] = None
    ) -> ToolResult:
        tool = self.tool_map.get(name)
        if not tool:
            return ToolFailure(error=f"Tool {name} is invalid")
        try:
            result = await tool(**tool_input)                          ######################è°ƒç”¨é¢„åˆ¶å¥½çš„å·¥å…·ç›´æ¥è¿è¡Œï¼ˆåšåŠ¨ä½œçš„å…³é”®ï¼‰
            return result
        except ToolError as e:
            return ToolFailure(error=e.message)
```

**æ‰§è¡Œé€»è¾‘**ï¼š

1. **è·å–å·¥å…·å®ä¾‹**ï¼šä» `tool_map` ä¸­è·å–å·¥å…·
2. **è°ƒç”¨å·¥å…·**ï¼š`await tool(**tool_input)` æ‰§è¡Œå·¥å…·
3. **è¿”å›ç»“æœ**ï¼šè¿”å› `ToolResult` æˆ– `ToolFailure`

---

## å…­ã€å†…å­˜ç®¡ç†ï¼šMemory

### 6.1 Memory ç»“æ„

```159:187:app/schema.py
class Memory(BaseModel):
    messages: List[Message] = Field(default_factory=list)
    max_messages: int = Field(default=100)

    def add_message(self, message: Message) -> None:
        """Add a message to memory"""
        self.messages.append(message)
        # Optional: Implement message limit
        if len(self.messages) > self.max_messages:
            self.messages = self.messages[-self.max_messages :]

    def add_messages(self, messages: List[Message]) -> None:
        """Add multiple messages to memory"""
        self.messages.extend(messages)
        # Optional: Implement message limit
        if len(self.messages) > self.max_messages:
            self.messages = self.messages[-self.max_messages :]

    def clear(self) -> None:
        """Clear all messages"""
        self.messages.clear()

    def get_recent_messages(self, n: int) -> List[Message]:
        """Get n most recent messages"""
        return self.messages[-n:]

    def to_dict_list(self) -> List[dict]:
        """Convert messages to list of dicts"""
        return [msg.to_dict() for msg in self.messages]
```

### 6.2 æ¶ˆæ¯ç±»å‹

- **USER**ï¼šç”¨æˆ·æ¶ˆæ¯ï¼ˆåˆå§‹è¯·æ±‚å’Œä¸‹ä¸€æ­¥æç¤ºï¼‰
- **ASSISTANT**ï¼šåŠ©æ‰‹æ¶ˆæ¯ï¼ˆLLM çš„å“åº”ï¼‰
- **TOOL**ï¼šå·¥å…·æ¶ˆæ¯ï¼ˆå·¥å…·æ‰§è¡Œç»“æœï¼‰
- **SYSTEM**ï¼šç³»ç»Ÿæ¶ˆæ¯ï¼ˆç³»ç»Ÿæç¤ºï¼‰

### 6.3 æ¶ˆæ¯æµ

```
ç”¨æˆ·è¾“å…¥ â†’ USER æ¶ˆæ¯ â†’ Memory
           â†“
        LLM å¤„ç†
           â†“
     ASSISTANT æ¶ˆæ¯ï¼ˆåŒ…å« tool_callsï¼‰â†’ Memory
           â†“
       æ‰§è¡Œå·¥å…·
           â†“
       TOOL æ¶ˆæ¯ï¼ˆå·¥å…·ç»“æœï¼‰â†’ Memory
           â†“
       ä¸‹ä¸€è½® Thinkï¼ˆåŒ…å«æ‰€æœ‰å†å²æ¶ˆæ¯ï¼‰
```

---

## ä¸ƒã€å·¥å…·ç³»ç»Ÿ

### 7.1 Manus çš„é»˜è®¤å·¥å…·

```34:42:app/agent/manus.py
    # Add general-purpose tools to the tool collection
    available_tools: ToolCollection = Field(
        default_factory=lambda: ToolCollection(
            PythonExecute(),
            BrowserUseTool(),
            StrReplaceEditor(),
            AskHuman(),
            Terminate(),
        )
    )
```

**é»˜è®¤å·¥å…·**ï¼š

1. **PythonExecute**ï¼šæ‰§è¡Œ Python ä»£ç 
2. **BrowserUseTool**ï¼šæµè§ˆå™¨æ“ä½œå·¥å…·
3. **StrReplaceEditor**ï¼šå­—ç¬¦ä¸²æ›¿æ¢ç¼–è¾‘å™¨
4. **AskHuman**ï¼šè¯¢é—®ç”¨æˆ·
5. **Terminate**ï¼šç»ˆæ­¢ Agentï¼ˆç‰¹æ®Šå·¥å…·ï¼‰

### 7.2 MCP å·¥å…·é›†æˆ

å¦‚æœé…ç½®äº† MCP æœåŠ¡å™¨ï¼ŒManus ä¼šåœ¨åˆå§‹åŒ–æ—¶è¿æ¥è¿™äº›æœåŠ¡å™¨ï¼Œå¹¶å°†å®ƒä»¬çš„å·¥å…·æ·»åŠ åˆ° `available_tools` ä¸­ã€‚

---

## å…«ã€çŠ¶æ€ç®¡ç†

### 8.1 AgentState æšä¸¾

```32:39:app/schema.py
class AgentState(str, Enum):
    """Agent execution states"""

    IDLE = "IDLE"
    RUNNING = "RUNNING"
    FINISHED = "FINISHED"
    ERROR = "ERROR"
```

### 8.2 çŠ¶æ€è½¬æ¢

```
IDLE â†’ RUNNING (agent.run() å¼€å§‹æ—¶)
  â†“
RUNNING â†’ FINISHED (é‡åˆ° Terminate å·¥å…·æˆ–å®Œæˆæ‰€æœ‰æ­¥éª¤)
  â†“
RUNNING â†’ ERROR (å‘ç”Ÿé”™è¯¯)
  â†“
FINISHED/ERROR â†’ IDLE (æ¸…ç†å)
```

---

## ä¹ã€å®Œæ•´è°ƒç”¨æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        main.py                              â”‚
â”‚  asyncio.run(main())                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   main() å‡½æ•°                                â”‚
â”‚  1. è§£æå‘½ä»¤è¡Œå‚æ•°                                           â”‚
â”‚  2. agent = await Manus.create()                            â”‚
â”‚  3. prompt = input("Enter your prompt: ")                   â”‚
â”‚  4. await agent.run(prompt)                                 â”‚
â”‚  5. await agent.cleanup()                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Manus.create() (åˆå§‹åŒ–)                         â”‚
â”‚  1. instance = cls(**kwargs)                                â”‚
â”‚  2. await instance.initialize_mcp_servers()                 â”‚
â”‚     - è¿æ¥é…ç½®çš„ MCP æœåŠ¡å™¨                                  â”‚
â”‚     - å°† MCP å·¥å…·æ·»åŠ åˆ° available_tools                     â”‚
â”‚  3. instance._initialized = True                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BaseAgent.run(request)                          â”‚
â”‚  1. æ£€æŸ¥çŠ¶æ€ (å¿…é¡»æ˜¯ IDLE)                                   â”‚
â”‚  2. update_memory("user", request)                          â”‚
â”‚  3. state_context(AgentState.RUNNING)                       â”‚
â”‚  4. while (current_step < max_steps and state != FINISHED): â”‚
â”‚       current_step += 1                                     â”‚
â”‚       step_result = await self.step()  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚       if is_stuck(): handle_stuck_state()                 â”‚ â”‚
â”‚  5. await SANDBOX_CLIENT.cleanup()                        â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                        â”‚                                      â”‚
                        â–¼                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚            ReActAgent.step()                                â”‚ â”‚
â”‚  1. should_act = await self.think()  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚
â”‚  2. if should_act:                                    â”‚    â”‚ â”‚
â”‚       return await self.act()  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
                        â”‚                                     â”‚ â”‚
                        â”‚                                     â”‚ â”‚
                        â–¼                                     â”‚ â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚        ToolCallAgent.think()                                â”‚ â”‚
â”‚  1. æ·»åŠ  next_step_prompt åˆ° messages                       â”‚ â”‚
â”‚  2. response = await self.llm.ask_tool(                    â”‚ â”‚
â”‚       messages=self.messages,                               â”‚ â”‚
â”‚       system_msgs=[system_prompt],                          â”‚ â”‚
â”‚       tools=available_tools.to_params(),                    â”‚ â”‚
â”‚       tool_choice=ToolChoice.AUTO                          â”‚ â”‚
â”‚     )                                                       â”‚ â”‚
â”‚  3. æå– tool_calls å’Œ content                             â”‚ â”‚
â”‚  4. åˆ›å»º assistant_msg å¹¶æ·»åŠ åˆ° memory                     â”‚ â”‚
â”‚  5. return bool(tool_calls)                                â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                        â”‚                                     â”‚ â”‚
                        â”‚                                     â”‚ â”‚
                        â–¼                                     â”‚ â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚           LLM.ask_tool()                                    â”‚ â”‚
â”‚  1. éªŒè¯å’Œæ ¼å¼åŒ–æ¶ˆæ¯                                         â”‚ â”‚
â”‚  2. è®¡ç®— token æ•°é‡                                         â”‚ â”‚
â”‚  3. æ£€æŸ¥ token é™åˆ¶                                         â”‚ â”‚
â”‚  4. await self.client.chat.completions.create(**params)    â”‚ â”‚
â”‚  5. è¿”å› ChatCompletionMessage                             â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                        â”‚                                     â”‚ â”‚
                        â”‚                                     â”‚ â”‚
                        â–¼                                     â”‚ â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚        ToolCallAgent.act()                                  â”‚ â”‚
â”‚  1. for command in self.tool_calls:                        â”‚ â”‚
â”‚       result = await self.execute_tool(command)  â†â”€â”€â”€â”    â”‚ â”‚
â”‚       åˆ›å»º tool_msg å¹¶æ·»åŠ åˆ° memory                    â”‚    â”‚ â”‚
â”‚  2. return "\n\n".join(results)                        â”‚    â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                        â”‚                                     â”‚ â”‚
                        â”‚                                     â”‚ â”‚
                        â–¼                                     â”‚ â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚      ToolCallAgent.execute_tool(command)                    â”‚ â”‚
â”‚  1. éªŒè¯å‘½ä»¤æ ¼å¼                                             â”‚ â”‚
â”‚  2. è§£æå‚æ•°: args = json.loads(command.function.arguments) â”‚ â”‚
â”‚  3. result = await self.available_tools.execute(           â”‚ â”‚
â”‚       name=name, tool_input=args                            â”‚ â”‚
â”‚     )                                                       â”‚ â”‚
â”‚  4. await self._handle_special_tool(name, result)          â”‚ â”‚
â”‚  5. return observation                                      â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                        â”‚                                     â”‚ â”‚
                        â”‚                                     â”‚ â”‚
                        â–¼                                     â”‚ â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚    ToolCollection.execute(name, tool_input)                 â”‚ â”‚
â”‚  1. tool = self.tool_map.get(name)                         â”‚ â”‚
â”‚  2. result = await tool(**tool_input)                      â”‚ â”‚
â”‚  3. return ToolResult                                       â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                        â”‚                                     â”‚ â”‚
                        â”‚                                     â”‚ â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                                                â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                    è¿”å› step_result
                        â”‚
                        â””â”€â”€â†’ ç»§ç»­å¾ªç¯æˆ–ç»“æŸ
```

---

## åã€å…³é”®é…ç½®

### 10.1 config.toml

é…ç½®æ–‡ä»¶ä½ç½®ï¼š`config/config.toml`

ä¸»è¦é…ç½®é¡¹ï¼š
- **LLM é…ç½®**ï¼šæ¨¡å‹ã€API keyã€base_url ç­‰
- **æ²™ç®±é…ç½®**ï¼šæ˜¯å¦ä½¿ç”¨æ²™ç®±
- **æµè§ˆå™¨é…ç½®**ï¼šChrome å®ä¾‹è·¯å¾„ç­‰
- **MCP é…ç½®**ï¼šMCP æœåŠ¡å™¨é…ç½®ï¼ˆä» mcp.json åŠ è½½ï¼‰

### 10.2 mcp.json

MCP æœåŠ¡å™¨é…ç½®æ–‡ä»¶ä½ç½®ï¼š`config/mcp.json`

---

## åä¸€ã€æ€»ç»“

### 11.1 æ ¸å¿ƒæ‰§è¡Œæµç¨‹

1. **åˆå§‹åŒ–é˜¶æ®µ**ï¼š
   - åˆ›å»º Manus å®ä¾‹
   - è¿æ¥ MCP æœåŠ¡å™¨
   - åˆå§‹åŒ–å·¥å…·é›†åˆ

2. **æ‰§è¡Œé˜¶æ®µ**ï¼ˆå¾ªç¯ï¼‰ï¼š
   - **Think**ï¼šLLM åˆ†æå½“å‰çŠ¶æ€ï¼Œå†³å®šä½¿ç”¨çš„å·¥å…·
   - **Act**ï¼šæ‰§è¡Œé€‰å®šçš„å·¥å…·
   - å°†ç»“æœæ·»åŠ åˆ° memory
   - é‡å¤ç›´åˆ°è¾¾åˆ° max_steps æˆ–é‡åˆ° Terminate å·¥å…·

3. **æ¸…ç†é˜¶æ®µ**ï¼š
   - æ¸…ç†æµè§ˆå™¨èµ„æº
   - æ–­å¼€ MCP è¿æ¥
   - æ¸…ç†æ²™ç®±èµ„æº

### 11.2 å…³é”®è®¾è®¡æ¨¡å¼

- **ReAct æ¨¡å¼**ï¼šThink-Act å¾ªç¯
- **å·¥å…·è°ƒç”¨æ¨¡å¼**ï¼šLLM é€šè¿‡å‡½æ•°è°ƒç”¨æ¥å£ä½¿ç”¨å·¥å…·
- **çŠ¶æ€ç®¡ç†**ï¼šAgentState ç®¡ç†æ‰§è¡ŒçŠ¶æ€
- **å†…å­˜ç®¡ç†**ï¼šMemory å­˜å‚¨å¯¹è¯å†å²

### 11.3 æ‰©å±•ç‚¹

- **æ·»åŠ æ–°å·¥å…·**ï¼šç»§æ‰¿ `BaseTool` å¹¶æ·»åŠ åˆ° `available_tools`
- **è‡ªå®šä¹‰ Agent**ï¼šç»§æ‰¿ `ToolCallAgent` æˆ– `ReActAgent`
- **MCP é›†æˆ**ï¼šé€šè¿‡é…ç½®æ–‡ä»¶æ·»åŠ  MCP æœåŠ¡å™¨

---

**æ–‡æ¡£ç”Ÿæˆæ—¶é—´**ï¼š2024å¹´
**ç‰ˆæœ¬**ï¼šåŸºäºå½“å‰ä»£ç åº“åˆ†æ
